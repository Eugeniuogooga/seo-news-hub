name: Run SEO scraper

on:
  schedule:
    - cron: '0 6 */3 * *'   # every 3 days at 06:00 UTC
  workflow_dispatch: {}

# allow the workflow to push to the repo
permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0                # full history so commits work

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install feedparser pyyaml beautifulsoup4

      - name: Run scraper
        run: |
          python scraper/scraper.py

      # This action safely commits and pushes only if files changed
      - name: Commit & push data/news.json
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: update news feed"
          file_pattern: data/news.json


