name: Run SEO scraper

on:
  schedule:
    - cron: '0 6 */3 * *'   # every 3 days at 06:00 UTC
  workflow_dispatch: {}

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0          # full history (needed for rebase)

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install feedparser pyyaml beautifulsoup4

      - name: Run scraper
        run: |
          python scraper/scraper.py

      # Make sure our local branch is up to date with remote
      - name: Sync with remote (rebase)
        run: |
          git config user.name  "seo-news-bot"
          git config user.email "bot@example.com"
          git pull --rebase origin main || true

      # Commit/push only if data/news.json changed
      - name: Commit & push data/news.json
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: update news feed"
          file_pattern: data/news.json
          push_options: '--force-with-lease'
